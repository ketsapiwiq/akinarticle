---
title: "Le fact-checking peut-il s’automatiser ?"
url: http://data.blog.lemonde.fr/2015/10/23/le-fact-checking-peut-il-sautomatiser/
keywords: journalisme,données,dun,recherche,faits,sautomatiser,peutil,laboratoires,fournir,propos,capables,factchecking,politique
---
Peut-on automatiser le fact-checking ? L'exercice, qui consiste à vérifier des faits, constitue le BA-ba du journalisme. Il n'en est pas moins devenu, depuis quelques années dans le monde entier, un format journalistique à part entière, notamment sur le web.

Souvent centré sur la vérification des propos et des chiffres des politiques, il tend également à englober aussi le « hoax busting », la chasse et le démontage de rumeurs. A l'heure des réseaux sociaux, où tout le monde dispose d'outils pour publier et diffuser de l'information, le fact-checking remplit un rôle de plus en plus nécessaire : revenir aux faits, lutter contre les intox et les dérives de la communication politique, mais aussi donner des clés pour un débat démocratique apaisé.

**Un exercice artisanal**

C'est ce que nous faisons, aux Décodeurs, depuis nos début sous forme de blog en 2009. Et nous sommes bien placés pour le savoir : la pratique est tout ce qu'il y a de plus artisanale. Vérifier un chiffre, une information, c'est commencer par fouiller nombre de sites à la recherche de sources fiables : institutions internationales, parlement, ONG... et d'en extraire des chiffres et des faits pertinents.

Aujourd'hui la donnée publique abonde. Et les moyens techniques de la traiter automatiquement également. En France, des chercheurs en informatique et des laboratoires de recherche travaillent sur ces questions, qu'il s'agisse de constitution et d'exploitation de bases de données ou de traitement automatique du langage.

**Une collaboration avec quatre laboratoires de recherche**

Voilà un an, deux chercheurs, Ioana Manolescu, directeur de recherche à l'INRIA Saclay, spécialiste des bases de données et responsable de l'équipe OAK, et Xavier Tannier, maître de conférences à l'Université Paris-Sud (Paris-Saclay) et chercheur au laboratoire [LIMSI-CNRS](http://www.limsi.fr/), spécialiste du traitement automatique du langage (TAL), sont venus nous proposer de travailler avec eux à une manière d'automatiser, sinon le fact-checking, du moins la contextualisation, l'enrichissement factuel, du débat politique, en développant des solutions capables de fournir automatiquement des faits, des chiffres, des données, selon un contexte, un propos, etc.

Notre projet, baptisé « ContentCheck », implique au total cinq institutions d'enseignement supérieur et de recherche ([INRIA Saclay qui le coordonne](http://www.inria.fr/centre/saclay/actualites/un-logiciel-de-fact-checking-pour-comprendre-le-monde-qui-nous-entoure?utm_content=buffer82887&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer), Université Paris Sud, [CNRS](https://lejournal.cnrs.fr/articles/un-logiciel-qui-decrypte-la-politique), Université Rennes 1, INSA Lyon) et quatre laboratoires de recherche. Il a été choisi par l'agence nationale de la recherche (ANR) qui le financera durant cinq ans. Il a en outre reçu un [Google Award qui assure un financement supplémentaire](https://archives.limsi.fr/Actualites/GoogleAward.html).

**Concevoir des logiciels capables de contextualiser l'information**

Nous ne sommes qu'aux débuts de nos travaux, mais nous rêvons de concevoir un outil capable, en temps réel, de fournir un contexte à une affirmation, un chiffre, un débat politique. Il pourra s'agir de texte, mais aussi de graphiques, qui pourront venir enrichir automatiquement un article, ou être proposés en rebond d'un propos politique.

Nous souhaitons aussi être capables de traiter le propos politique comme un flux de données, afin d'y repérer les éléments de langage, de cartographier les positionnements, de détecter des argumentaires... Evidemment, la perspective de la présidentielle 2017 nous ouvre un champ d'application immédiat.

**Vers un journalisme augmenté**

Notre projet se pose une question ambitieuse, celui du journalisme « augmenté » : à l'heure des algorithmes et de ce grand fourre-tout qu'on résume souvent sous le terme de « big data », notre métier reste très artisanal et peine à tirer profit des technologies et des données qui, pourtant, abondent.

L'objet journalistique de base reste l'article, soit un texte figé, qui au mieux sera manuellement mis à jour, quand on pourrait, on devrait penser des objets interactifs, connectés à des flux de données, et capables de s'actualiser ou de s'enrichir (d'un graphique, d'un lien, d'une vidéo...) seuls en fonction d'un contexte. Le datajournalisme est un pas dans cette direction.

Ainsi, nous avons créé et lancé sur LeMonde.fr une architecture de données, qui nous permet non seulement de [fournir tous les résultats électoraux dans les 36 000 communes de France](http://www.lemonde.fr/carte-departements/), mais aussi de proposer une série d'autres informations, pratiques et statistiques, régulièrement actualisés. Les textes qui composent ces pages ont été générés par un algorithme. Et derrière ces 36 000 pages, on trouve une technologie capable de fournir aux rédacteurs le matériel pour concevoir des traitements statistiques croisés, des cartes, des analyses... Et ce n'est là qu'une première étape.

Le partenariat noué avec ces chercheurs nous permettra, nous l'espérons, d'avancer encore sur cette voie d'un journalisme non pas « remplacé par les robots » comme certains le craignent, mais où le logiciel vient, au contraire aider, assister, augmenter les rédactions et les journalistes, et offrent de nouvelles manières d'analyser, d'illustrer, de faire comprendre la France et le monde.

**Samuel Laurent**

 

[Signaler ce contenu comme inapproprié](http://www.contact-moderation.com/abuse.asp?origine=LM&language=FR&content_id=blog-2687689)
